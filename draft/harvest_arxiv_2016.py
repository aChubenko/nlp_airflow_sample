import time
import psycopg2
from sickle import Sickle
from sickle.oaiexceptions import OAIError
from requests.exceptions import HTTPError

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL
PG_CONN = {
    "host": "localhost",
    "port": 5432,
    "dbname": "arxiv",
    "user": "postgres",
    "password": "your_password"
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Sickle
sickle = Sickle("http://export.arxiv.org/oai2")

# –û–±—ë—Ä—Ç–∫–∞ —Å –∞–≤—Ç–æ–ø–æ–≤—Ç–æ—Ä–æ–º –ø—Ä–∏ 503
def safe_list_records(**kwargs):
    while True:
        try:
            return sickle.ListRecords(**kwargs)
        except HTTPError as e:
            if e.response.status_code == 503:
                retry_after = int(e.response.headers.get("Retry-After", "30"))
                print(f"‚è≥ arXiv –æ—Ç–≤–µ—Ç–∏–ª 503. –ñ–¥—ë–º {retry_after} —Å–µ–∫...")
                time.sleep(retry_after)
            else:
                raise

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞—Ç—á–∞ –≤ PostgreSQL
def save_batch_to_db(batch):
    if not batch:
        return
    with psycopg2.connect(**PG_CONN) as conn:
        with conn.cursor() as cur:
            for rec in batch:
                cur.execute("""
                    INSERT INTO arxiv_articles (identifier, title, abstract, authors, created)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT (identifier) DO NOTHING
                """, (
                    rec["id"],
                    rec["title"],
                    rec["abstract"],
                    ", ".join(rec["authors"]),
                    rec["created"]
                ))

def save_batch_to_db2(batch):
    print(f"save_batch_to_db2 {len(batch)}")

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–æ –≤—Å–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
def harvest_arxiv(year: int):
    total = 0
    buffer = []

    # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    records = safe_list_records(
        metadataPrefix="arXiv",
        **{
            "from": f"{year}-01-01",
            "until": f"{year}-12-31"
        }
    )

    while True:
        for record in records:
            if record.deleted:
                continue

            meta = record.metadata
            buffer.append({
                "id": record.header.identifier,
                "title": meta.get("title", [""])[0],
                "abstract": meta.get("abstract", [""])[0],
                "authors": meta.get("creator", []),
                "created": meta.get("created", [""])[0],
            })

            # üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–µ 1000 –∑–∞–ø–∏—Å–µ–π
            if len(buffer) >= 1000:
                print(f"üì¶ –°–æ—Ö—Ä–∞–Ω—è–µ–º {len(buffer)} –∑–∞–ø–∏—Å–µ–π...")
                time.sleep(10)
                save_batch_to_db2(buffer)
                total += len(buffer)
                print(f"‚úÖ –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total}")
                buffer = []

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        token = records.resumption_token
        if token:
            print(f"token batch size : {len(buffer)}")
            time.sleep(10)
            print(f"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏–º –ø–æ resumptionToken: {token}")
            records = safe_list_records(
                metadataPrefix="arXiv",
                resumptionToken=token
            )
        else:
            print("‚úÖ –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–π–¥–µ–Ω—ã.")
            break

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
    if buffer:
        print(f"üì¶ –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞—Ç—á: {len(buffer)} –∑–∞–ø–∏—Å–µ–π")
        save_batch_to_db2(buffer)
        total += len(buffer)

    print(f"üéâ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total} –∑–∞–ø–∏—Å–µ–π")

if __name__ == "__main__":
    harvest_arxiv(2016)
